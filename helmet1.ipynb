{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1aFF5qkMYdI",
        "outputId": "e693416b-9afe-4485-cdb9-2a09dddc62bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.199-py3-none-any.whl (644 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m644.5/644.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (17.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.199\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gO3zt6c4_tt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T2GoOu1Mtv5",
        "outputId": "0dceaa30-c139-4c5e-a870-6bb964cfd2b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY1dI2zFMwVu",
        "outputId": "cc7fc80a-5abe-4645-c921-aedc3e86853d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.23M/6.23M [00:00<00:00, 106MB/s]\n",
            "Ultralytics YOLOv8.0.199 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 444, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 242, in predict\n",
            "    return self.predictor.predict_cli(source=source) if is_cli else self.predictor(source=source, stream=stream)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\", line 205, in predict_cli\n",
            "    for _ in gen:  # running CLI inference without accumulating any outputs (do not modify)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 35, in generator_context\n",
            "    response = gen.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\", line 235, in stream_inference\n",
            "    self.setup_source(source if source is not None else self.args.source)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\", line 213, in setup_source\n",
            "    self.dataset = load_inference_source(source=source,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/build.py\", line 172, in load_inference_source\n",
            "    dataset = LoadImages(source, imgsz=imgsz, vid_stride=vid_stride)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/loaders.py\", line 287, in __init__\n",
            "    raise FileNotFoundError(f'{p} does not exist')\n",
            "FileNotFoundError: /content/hard_hat_workers993.png does not exist\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=predict model=yolov8n.pt source=\"/content/hard_hat_workers993.png\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MHap3rmOPYZ",
        "outputId": "c1da7cf8-c964-47c6-a306-13f7ea3cbd9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.9/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install ultralytics==8.0.20\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSFUWwYFOV7H"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUavV055Obwu",
        "outputId": "91f6b22d-89b8-4b7e-9792-e87a925e8af6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '{HOME}'\n",
            "/content\n",
            "2023-10-17 08:53:41.803964: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-17 08:53:43.626056: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/cfg/__init__.py\", line 249, in entrypoint\n",
            "    getattr(model, mode)(verbose=True, **overrides)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/model.py\", line 146, in predict\n",
            "    return self.predictor(source=source, stream=stream, verbose=verbose)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/predictor.py\", line 158, in __call__\n",
            "    return list(self.stream_inference(source, model, verbose))  # merge list of Result into one\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/predictor.py\", line 173, in stream_inference\n",
            "    self.setup_source(source)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/engine/predictor.py\", line 139, in setup_source\n",
            "    self.dataset = LoadImages(source,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/yolo/data/dataloaders/stream_loaders.py\", line 172, in __init__\n",
            "    raise FileNotFoundError(f'{p} does not exist')\n",
            "FileNotFoundError: /content/hard_hat_workers993.png does not exist\n",
            "Sentry is attempting to send 2 pending events\n",
            "Waiting up to 2 seconds\n",
            "Press Ctrl-C to quit\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "!yolo task=detect mode=predict model=yolov8n.pt conf=0.25 source='/content/hard_hat_workers993.png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLx_rnqs4WSP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V7RwZ74OvR7",
        "outputId": "943d988a-2fb6-402c-ca27-c1292d22f321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yauWEhCGQYd6",
        "outputId": "62b079d8-e5ba-4c16-af40-081fac31ae13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5OnIpeSQnpX",
        "outputId": "86a44127-a835-43b6-cd0c-5581f7af434d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Colab Notebooks'   data.yaml\t\t   extracted_data1.xlsx   Footwear_data.xlsx   yolov8n.pt\n",
            " data\t\t    extracted_1data.xlsx   filtered_data.xlsx\t  runs\t\t       yolov8s.pt\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwh-7wUhQwyY",
        "outputId": "24cead4c-84b8-42f5-e880-bea31e7b7ece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n",
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.yaml, data=data.yaml, epochs=25, patience=50, batch=16, imgsz=224, save=True, cache=False, device=, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=runs/detect/train14\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 22.4MB/s]\n",
            "2023-10-17 08:54:28.147300: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-17 08:54:29.888087: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.Conv                  [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.C2f                   [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.C2f                   [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.Conv                  [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.C2f                   [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.SPPF                  [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.C2f                   [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.Conv                  [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.C2f                   [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2117983  ultralytics.nn.modules.Detect                [5, [128, 256, 512]]          \n",
            "Model summary: 225 layers, 11137535 parameters, 11137519 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/data/train/labels.cache... 120 images, 0 backgrounds, 0 corrupt: 100% 120/120 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/data/valid/labels.cache... 31 images, 0 backgrounds, 0 corrupt: 100% 31/31 [00:00<?, ?it/s]\n",
            "Image sizes 224 train, 224 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train14\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/25         0G      2.314      4.882       1.59         67        224: 100% 8/8 [00:43<00:00,  5.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:15<00:00, 15.05s/it]\n",
            "                   all         31        101      0.435     0.0286     0.0131    0.00362\n",
            "                Helmet         31         18          1          0    0.00477    0.00199\n",
            "               Goggles         31          9          0          0          0          0\n",
            "                Jacket         31         14      0.176      0.143      0.047    0.00888\n",
            "                Gloves         31         52          1          0     0.0118    0.00606\n",
            "              Footwear         31          8          0          0    0.00214    0.00116\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/25         0G      2.107      3.632      1.484         70        224: 100% 8/8 [00:37<00:00,  4.63s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:04<00:00,  4.29s/it]\n",
            "                   all         31        101      0.369      0.266      0.234      0.112\n",
            "                Helmet         31         18      0.561      0.833      0.821      0.445\n",
            "               Goggles         31          9          0          0    0.00574    0.00208\n",
            "                Jacket         31         14          0          0     0.0927       0.03\n",
            "                Gloves         31         52          1          0     0.0291     0.0116\n",
            "              Footwear         31          8      0.284      0.496       0.22     0.0716\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/25         0G      1.958      2.518      1.388         92        224: 100% 8/8 [00:35<00:00,  4.48s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:05<00:00,  5.33s/it]\n",
            "                   all         31        101      0.831      0.314       0.42      0.214\n",
            "                Helmet         31         18      0.841      0.667      0.868      0.557\n",
            "               Goggles         31          9          1          0     0.0321    0.00939\n",
            "                Jacket         31         14      0.677      0.151      0.338      0.231\n",
            "                Gloves         31         52          1          0      0.171     0.0785\n",
            "              Footwear         31          8      0.638       0.75      0.689      0.194\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/25         0G      1.905      1.959      1.327         73        224: 100% 8/8 [00:35<00:00,  4.43s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:04<00:00,  4.23s/it]\n",
            "                   all         31        101      0.696      0.382      0.439       0.25\n",
            "                Helmet         31         18       0.87      0.833      0.959      0.661\n",
            "               Goggles         31          9          1          0     0.0964     0.0286\n",
            "                Jacket         31         14      0.926      0.286       0.51      0.314\n",
            "                Gloves         31         52      0.265      0.288      0.245      0.113\n",
            "              Footwear         31          8      0.419        0.5      0.382      0.131\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/25         0G      1.736      1.588      1.268         78        224: 100% 8/8 [00:36<00:00,  4.54s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:04<00:00,  4.05s/it]\n",
            "                   all         31        101      0.599      0.449      0.557       0.29\n",
            "                Helmet         31         18          1      0.789      0.934      0.636\n",
            "               Goggles         31          9          0          0      0.105     0.0484\n",
            "                Jacket         31         14      0.946      0.286      0.536      0.303\n",
            "                Gloves         31         52       0.37      0.293      0.284      0.129\n",
            "              Footwear         31          8      0.678      0.875      0.927      0.335\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/25         0G       1.69      1.414      1.225         96        224: 100% 8/8 [00:37<00:00,  4.75s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.85s/it]\n",
            "                   all         31        101      0.585      0.612      0.591      0.294\n",
            "                Helmet         31         18        0.9      0.833        0.9      0.613\n",
            "               Goggles         31          9       0.19      0.222      0.169     0.0684\n",
            "                Jacket         31         14      0.797      0.571      0.702       0.32\n",
            "                Gloves         31         52      0.241      0.556      0.251       0.11\n",
            "              Footwear         31          8      0.795      0.875      0.935      0.359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/25         0G      1.643      1.382      1.239         55        224: 100% 8/8 [00:39<00:00,  4.92s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.62s/it]\n",
            "                   all         31        101      0.571        0.7      0.653      0.356\n",
            "                Helmet         31         18      0.915      0.944      0.946       0.65\n",
            "               Goggles         31          9       0.23      0.444      0.326     0.0991\n",
            "                Jacket         31         14      0.651      0.536      0.667       0.43\n",
            "                Gloves         31         52      0.303      0.577      0.345      0.161\n",
            "              Footwear         31          8      0.758          1      0.982      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/25         0G      1.613      1.299      1.181         66        224: 100% 8/8 [00:37<00:00,  4.65s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.58s/it]\n",
            "                   all         31        101      0.658      0.772      0.726      0.396\n",
            "                Helmet         31         18      0.915          1      0.981      0.668\n",
            "               Goggles         31          9      0.477      0.444      0.444       0.17\n",
            "                Jacket         31         14      0.757      0.857      0.885      0.534\n",
            "                Gloves         31         52      0.356      0.558       0.39      0.207\n",
            "              Footwear         31          8      0.785          1      0.928      0.403\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/25         0G      1.582      1.216      1.158        114        224: 100% 8/8 [00:36<00:00,  4.53s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:04<00:00,  4.20s/it]\n",
            "                   all         31        101      0.571      0.663      0.655      0.385\n",
            "                Helmet         31         18      0.865          1      0.978      0.697\n",
            "               Goggles         31          9      0.171      0.333      0.248      0.145\n",
            "                Jacket         31         14      0.606      0.857      0.857       0.61\n",
            "                Gloves         31         52      0.211       0.75      0.318      0.162\n",
            "              Footwear         31          8          1      0.375      0.873      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/25         0G       1.59      1.163      1.201         55        224: 100% 8/8 [00:33<00:00,  4.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:05<00:00,  5.01s/it]\n",
            "                   all         31        101      0.702      0.724      0.717      0.439\n",
            "                Helmet         31         18      0.946          1      0.987      0.707\n",
            "               Goggles         31          9      0.493      0.333      0.317      0.177\n",
            "                Jacket         31         14      0.797      0.786      0.865      0.577\n",
            "                Gloves         31         52      0.426        0.5      0.448      0.241\n",
            "              Footwear         31          8      0.848          1      0.967      0.494\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/25         0G      1.624      1.211      1.163         68        224: 100% 8/8 [00:34<00:00,  4.31s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:05<00:00,  5.12s/it]\n",
            "                   all         31        101      0.747      0.724      0.788      0.453\n",
            "                Helmet         31         18      0.883          1      0.992      0.695\n",
            "               Goggles         31          9      0.461       0.29      0.517      0.245\n",
            "                Jacket         31         14      0.832      0.857      0.867      0.564\n",
            "                Gloves         31         52      0.583      0.596      0.591       0.35\n",
            "              Footwear         31          8      0.974      0.875      0.971      0.412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/25         0G      1.539      1.055      1.121         45        224: 100% 8/8 [00:34<00:00,  4.32s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:05<00:00,  5.01s/it]\n",
            "                   all         31        101      0.823      0.687       0.75      0.434\n",
            "                Helmet         31         18      0.884          1      0.995      0.738\n",
            "               Goggles         31          9      0.865      0.222      0.398      0.209\n",
            "                Jacket         31         14       0.81      0.857      0.791      0.528\n",
            "                Gloves         31         52      0.556      0.712      0.633      0.347\n",
            "              Footwear         31          8          1      0.644      0.935      0.349\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/25         0G      1.521      1.062       1.11         57        224: 100% 8/8 [00:34<00:00,  4.32s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:04<00:00,  4.32s/it]\n",
            "                   all         31        101      0.813       0.74      0.801      0.485\n",
            "                Helmet         31         18      0.966          1      0.995      0.722\n",
            "               Goggles         31          9      0.796      0.333      0.499      0.266\n",
            "                Jacket         31         14      0.782      0.857      0.896      0.593\n",
            "                Gloves         31         52      0.604      0.635      0.644      0.374\n",
            "              Footwear         31          8      0.917      0.875      0.971       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/25         0G      1.482     0.9708      1.097         46        224: 100% 8/8 [00:36<00:00,  4.50s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:04<00:00,  4.44s/it]\n",
            "                   all         31        101      0.796      0.714      0.787      0.466\n",
            "                Helmet         31         18      0.965          1      0.995        0.7\n",
            "               Goggles         31          9      0.646      0.409      0.485      0.236\n",
            "                Jacket         31         14      0.797      0.844      0.838      0.623\n",
            "                Gloves         31         52      0.734      0.442      0.646      0.364\n",
            "              Footwear         31          8       0.84      0.875      0.971      0.409\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/25         0G      1.484      1.003      1.099         79        224: 100% 8/8 [00:35<00:00,  4.38s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.96s/it]\n",
            "                   all         31        101      0.828      0.763      0.822      0.492\n",
            "                Helmet         31         18      0.991          1      0.995      0.707\n",
            "               Goggles         31          9      0.713      0.444      0.605      0.306\n",
            "                Jacket         31         14      0.922      0.847      0.852      0.621\n",
            "                Gloves         31         52      0.634      0.615      0.678       0.38\n",
            "              Footwear         31          8      0.879      0.908      0.982      0.449\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/25         0G      1.446      1.102      1.067         36        224: 100% 8/8 [00:34<00:00,  4.36s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.44s/it]\n",
            "                   all         31        101      0.887      0.745      0.807      0.485\n",
            "                Helmet         31         18      0.992          1      0.995      0.699\n",
            "               Goggles         31          9      0.714      0.556      0.532      0.298\n",
            "                Jacket         31         14      0.883      0.786      0.867      0.598\n",
            "                Gloves         31         52      0.846      0.422      0.648      0.344\n",
            "              Footwear         31          8          1      0.963      0.995      0.488\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/25         0G      1.399     0.9021      1.055         44        224: 100% 8/8 [00:33<00:00,  4.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.50s/it]\n",
            "                   all         31        101      0.865      0.793      0.839      0.488\n",
            "                Helmet         31         18      0.979          1      0.995      0.663\n",
            "               Goggles         31          9      0.744      0.667      0.617      0.274\n",
            "                Jacket         31         14      0.871      0.857      0.875      0.617\n",
            "                Gloves         31         52       0.84      0.442      0.714      0.394\n",
            "              Footwear         31          8       0.89          1      0.995      0.492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/25         0G      1.361     0.8832      1.076         37        224: 100% 8/8 [00:34<00:00,  4.28s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.72s/it]\n",
            "                   all         31        101      0.867      0.793      0.841      0.497\n",
            "                Helmet         31         18      0.976          1      0.995      0.686\n",
            "               Goggles         31          9      0.742      0.667       0.68      0.326\n",
            "                Jacket         31         14      0.931      0.857      0.859      0.598\n",
            "                Gloves         31         52      0.786      0.566      0.744      0.428\n",
            "              Footwear         31          8      0.898      0.875      0.928      0.445\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/25         0G      1.366     0.8437      1.058         30        224: 100% 8/8 [00:33<00:00,  4.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.84s/it]\n",
            "                   all         31        101      0.898      0.809      0.857      0.484\n",
            "                Helmet         31         18          1      0.992      0.995      0.681\n",
            "               Goggles         31          9      0.842      0.667      0.662      0.294\n",
            "                Jacket         31         14      0.893      0.857       0.89       0.62\n",
            "                Gloves         31         52      0.797      0.654      0.795      0.449\n",
            "              Footwear         31          8      0.956      0.875      0.944      0.378\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/25         0G      1.356      0.838      1.055         69        224: 100% 8/8 [00:32<00:00,  4.06s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:05<00:00,  5.96s/it]\n",
            "                   all         31        101      0.923      0.756      0.854      0.476\n",
            "                Helmet         31         18          1      0.993      0.995      0.647\n",
            "               Goggles         31          9          1      0.546       0.68      0.311\n",
            "                Jacket         31         14      0.838      0.857      0.906      0.628\n",
            "                Gloves         31         52      0.827      0.635      0.783       0.45\n",
            "              Footwear         31          8       0.95       0.75      0.907      0.344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/25         0G      1.371     0.8066      1.031         48        224: 100% 8/8 [00:35<00:00,  4.39s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:04<00:00,  4.72s/it]\n",
            "                   all         31        101      0.815      0.826       0.85      0.471\n",
            "                Helmet         31         18      0.981          1      0.995      0.632\n",
            "               Goggles         31          9      0.731      0.667      0.687      0.284\n",
            "                Jacket         31         14      0.754      0.857      0.889      0.623\n",
            "                Gloves         31         52      0.732      0.731      0.772      0.439\n",
            "              Footwear         31          8      0.875      0.875      0.909      0.376\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/25         0G      1.284     0.7564      1.029         59        224: 100% 8/8 [00:33<00:00,  4.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.62s/it]\n",
            "                   all         31        101      0.912      0.771      0.857      0.475\n",
            "                Helmet         31         18      0.995          1      0.995       0.64\n",
            "               Goggles         31          9      0.885      0.667      0.743      0.318\n",
            "                Jacket         31         14      0.908      0.786      0.876      0.613\n",
            "                Gloves         31         52      0.794      0.654       0.77      0.431\n",
            "              Footwear         31          8      0.977       0.75      0.899      0.371\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/25         0G      1.312     0.7761      1.041         38        224: 100% 8/8 [00:34<00:00,  4.32s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.65s/it]\n",
            "                   all         31        101       0.93      0.747      0.864      0.484\n",
            "                Helmet         31         18      0.994          1      0.995      0.633\n",
            "               Goggles         31          9      0.867      0.667      0.737      0.299\n",
            "                Jacket         31         14          1      0.782      0.899      0.615\n",
            "                Gloves         31         52      0.789      0.635      0.782      0.448\n",
            "              Footwear         31          8          1      0.653      0.908      0.422\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/25         0G      1.298     0.7334      1.013         34        224: 100% 8/8 [00:33<00:00,  4.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:03<00:00,  3.62s/it]\n",
            "                   all         31        101      0.921      0.754       0.87      0.502\n",
            "                Helmet         31         18      0.988          1      0.995      0.668\n",
            "               Goggles         31          9       0.93      0.667      0.792      0.348\n",
            "                Jacket         31         14      0.957      0.786      0.896      0.648\n",
            "                Gloves         31         52      0.728      0.654      0.763      0.444\n",
            "              Footwear         31          8          1      0.664      0.906      0.403\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/25         0G      1.256      0.761      1.023         30        224: 100% 8/8 [00:33<00:00,  4.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:04<00:00,  4.58s/it]\n",
            "                   all         31        101      0.796      0.834      0.854      0.494\n",
            "                Helmet         31         18      0.957          1      0.995      0.642\n",
            "               Goggles         31          9      0.515      0.709      0.726      0.335\n",
            "                Jacket         31         14      0.921      0.857      0.907      0.651\n",
            "                Gloves         31         52      0.662      0.731      0.748      0.434\n",
            "              Footwear         31          8      0.924      0.875      0.893      0.408\n",
            "\n",
            "25 epochs completed in 0.289 hours.\n",
            "Optimizer stripped from runs/detect/train14/weights/last.pt, 22.5MB\n",
            "Optimizer stripped from runs/detect/train14/weights/best.pt, 22.5MB\n",
            "\n",
            "Validating runs/detect/train14/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.12 torch-2.0.1+cu118 CPU\n",
            "Model summary (fused): 168 layers, 11127519 parameters, 0 gradients, 28.4 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:04<00:00,  4.50s/it]\n",
            "                   all         31        101      0.919      0.754       0.87      0.502\n",
            "                Helmet         31         18      0.988          1      0.995      0.668\n",
            "               Goggles         31          9      0.927      0.667      0.792      0.348\n",
            "                Jacket         31         14      0.956      0.786      0.896      0.647\n",
            "                Gloves         31         52      0.724      0.654      0.763      0.443\n",
            "              Footwear         31          8          1      0.664      0.906      0.403\n",
            "Speed: 0.4ms pre-process, 133.2ms inference, 0.0ms loss, 1.1ms post-process per image\n",
            "Results saved to \u001b[1mruns/detect/train14\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive\n",
        "\n",
        "!yolo task=detect mode=train model=yolov8s.pt data= data.yaml epochs=25 imgsz=224 plots=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ztRAOysywKn6",
        "outputId": "e9522ae7-7efb-47d2-8424-56a143f9adb7"
      },
      "outputs": [
        {
          "ename": "CalledProcessError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-740d95c1cc12>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Execute the command and capture the output line by line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0moutput_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0m\u001b[1;32m    422\u001b[0m                **kwargs).stdout\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    527\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '['yolo', 'task=detect', 'mode=predict', 'model=/content/drive/MyDrive/runs/detect/train9/weights/best.pt', 'conf=0.2', \"source='/content/pexels-everett-bumstead-5423610 (1080p) (1).mp4'\", 'save=True']' returned non-zero exit status 1."
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "# Define the command as a list of arguments\n",
        "command = [\n",
        "    \"yolo\",\n",
        "    \"task=detect\",\n",
        "    \"mode=predict\",\n",
        "    \"model=/content/drive/MyDrive/runs/detect/train9/weights/best.pt\",\n",
        "    \"conf=0.2\",\n",
        "    \"source='/content/pexels-everett-bumstead-5423610 (1080p) (1).mp4'\",\n",
        "    \"save=True\"\n",
        "]\n",
        "\n",
        "# Execute the command and capture the output line by line\n",
        "output = subprocess.check_output(command, text=True)\n",
        "output_lines = output.split('\\n')\n",
        "\n",
        "# Initialize a list to store the extracted data\n",
        "extracted_data = []\n",
        "\n",
        "# Define regular expressions to match item names, quantities, and update times\n",
        "item_pattern = r'(Helmet|Jacket|Footwear|Gloves|Goggles)'\n",
        "quantity_pattern = r'(\\d+) (Helmet|Jacket|Footwear|Gloves|Goggles)'\n",
        "time_pattern = r'(\\d+\\.\\d+)ms'\n",
        "\n",
        "# Loop through each line in the list\n",
        "for line in output_lines:\n",
        "    # Initialize a dictionary to store the extracted data for this line\n",
        "    data_entry = {'Item Name': None, 'Quantity': None, 'Quantity Name': None, 'Update Time (ms)': None}\n",
        "\n",
        "    # Extract item name\n",
        "    item_match = re.search(item_pattern, line)\n",
        "    if item_match:\n",
        "        data_entry['Item Name'] = item_match.group(0)\n",
        "\n",
        "    # Extract quantity\n",
        "    quantity_match = re.search(quantity_pattern, line)\n",
        "    if quantity_match:\n",
        "        data_entry['Quantity'] = quantity_match.group(1)\n",
        "        data_entry['Quantity Name'] = quantity_match.group(2)\n",
        "\n",
        "    # Extract update time\n",
        "    time_match = re.search(time_pattern, line)\n",
        "    if time_match:\n",
        "        data_entry['Update Time (ms)'] = time_match.group(1)\n",
        "\n",
        "    # Append the extracted data to the list\n",
        "    extracted_data.append(data_entry)\n",
        "\n",
        "# Create a DataFrame from the extracted data\n",
        "df = pd.DataFrame(extracted_data)\n",
        "\n",
        "# Save the data to an Excel file\n",
        "df.to_excel('extracted_1data.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "A2uG6heVloTS"
      },
      "outputs": [],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ifT5jc6RHTOw"
      },
      "outputs": [],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gbINovseSizK"
      },
      "outputs": [],
      "source": [
        "x=!yolo task=detect mode=predict model=/content/drive/MyDrive/runs/detect/train9/weights/best.pt conf=0.2 source='/content/pexels_videos_2648 (1080p).mp4' save=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fZJBmmN6oI-n"
      },
      "outputs": [],
      "source": [
        "!pip install twilio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ryM2NaecKDGN"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "def extract_helmet_jacket_data(input_text):\n",
        "    # Initialize lists to store the extracted data\n",
        "    extracted_data = []\n",
        "\n",
        "    # Define regular expressions to match item names, quantities, and update times\n",
        "    item_pattern = r'(Helmet|Jacket|Footwear|Gloves|Goggles)'\n",
        "    quantity_pattern = r'(\\d+) (Helmet|Jacket|Footwear|Gloves|Goggles)'\n",
        "    time_pattern = r'(\\d+\\.\\d+)ms'\n",
        "\n",
        "    # Create a set to keep track of items present in the text\n",
        "    present_items = set()\n",
        "\n",
        "    # Loop through each line in the input text\n",
        "    for line in input_text:\n",
        "        # Initialize a dictionary to store the extracted data for this line\n",
        "        data_entry = {}\n",
        "\n",
        "        # Extract item name\n",
        "        item_match = re.search(item_pattern, line)\n",
        "        if item_match:\n",
        "            item_name = item_match.group(0)\n",
        "            present_items.add(item_name)  # Add the item to the set\n",
        "\n",
        "        # Extract quantity\n",
        "        quantity_match = re.search(quantity_pattern, line)\n",
        "        if quantity_match:\n",
        "            data_entry['Quantity'] = quantity_match.group(1)\n",
        "            data_entry['Quantity Name'] = quantity_match.group(2)\n",
        "        else:\n",
        "            data_entry['Quantity'] = 0  # Set quantity to 0 for lines without a match\n",
        "            data_entry['Quantity Name'] = None\n",
        "\n",
        "        # Extract update time\n",
        "        time_match = re.search(time_pattern, line)\n",
        "        if time_match:\n",
        "            data_entry['Update Time (ms)'] = time_match.group(1)\n",
        "        else:\n",
        "            data_entry['Update Time (ms)'] = None\n",
        "\n",
        "        # Append the extracted data to the list\n",
        "        extracted_data.append(data_entry)\n",
        "\n",
        "    # Add items with quantity 0 that are not present in the text\n",
        "    for item_name in set(['Helmet', 'Jacket', 'Footwear', 'Gloves', 'Goggles']) - present_items:\n",
        "        extracted_data.append({'Quantity': 0, 'Quantity Name': item_name, 'Update Time (ms)': None})\n",
        "\n",
        "    return extracted_data\n",
        "\n",
        "result = extract_helmet_jacket_data(x)\n",
        "\n",
        "# Create a DataFrame from the extracted data\n",
        "df = pd.DataFrame(result)\n",
        "\n",
        "# Display the data in a table format\n",
        "filtered_df = df[(df['Quantity'] == '2') & (df['Quantity Name'] == 'Helmet')]\n",
        "\n",
        "\n",
        "df.to_excel('filtered_data.xlsx', index=False)\n",
        "print(filtered_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ruKrU4TevgMw"
      },
      "outputs": [],
      "source": [
        "from twilio.rest import Client\n",
        "\n",
        "account_sid = 'AC27bd2869f8a9a684380671d567158a52'\n",
        "auth_token = '541d7173cc143722ba8ddaef57eb79dc'\n",
        "client = Client(account_sid, auth_token)\n",
        "\n",
        "message = client.messages.create(\n",
        "  from_='+15736779819',\n",
        "  body='mc bro',\n",
        "  to='+918827661310'\n",
        ")\n",
        "\n",
        "print(message.sid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l1tmGGhBXI4s"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "def extract_helmet_jacket_data(input_text):\n",
        "    # Initialize lists to store the extracted data\n",
        "    extracted_data = []\n",
        "\n",
        "    # Define regular expressions to match item names, quantities, and update times\n",
        "    item_pattern = r'(Helmet|Jacket|Footwear|Gloves|Goggles)'\n",
        "    quantity_pattern = r'(\\d+) (Helmet|Jacket|Footwear|Gloves|Goggles)'\n",
        "    time_pattern = r'(\\d+\\.\\d+)ms'\n",
        "\n",
        "    # Create a set to keep track of items present in the text\n",
        "    present_items = set()\n",
        "\n",
        "    # Split the input_text into lines\n",
        "    lines = input_text.split('\\n')\n",
        "\n",
        "    # Loop through each line in the input text\n",
        "    for line in lines:\n",
        "        # Initialize a dictionary to store the extracted data for this line\n",
        "        data_entry = {}\n",
        "\n",
        "        # Extract item name\n",
        "        item_match = re.search(item_pattern, line)\n",
        "        if item_match:\n",
        "            item_name = item_match.group(0)\n",
        "            present_items.add(item_name)  # Add the item to the set\n",
        "\n",
        "        # Extract quantity\n",
        "        quantity_match = re.search(quantity_pattern, line)\n",
        "        if quantity_match:\n",
        "            data_entry['Quantity'] = quantity_match.group(1)\n",
        "            data_entry['Quantity Name'] = quantity_match.group(2)\n",
        "        else:\n",
        "            data_entry['Quantity'] = 0  # Set quantity to 0 for lines without a match\n",
        "            data_entry['Quantity Name'] = None\n",
        "\n",
        "        # Extract update time\n",
        "        time_match = re.search(time_pattern, line)\n",
        "        if time_match:\n",
        "            data_entry['Update Time (ms)'] = time_match.group(1)\n",
        "        else:\n",
        "            data_entry['Update Time (ms)'] = None\n",
        "\n",
        "        # Append the extracted data to the list\n",
        "        extracted_data.append(data_entry)\n",
        "\n",
        "    # Add items with quantity 0 that are not present in the text\n",
        "    for item_name in set(['Helmet', 'Jacket', 'Footwear', 'Gloves', 'Goggles']) - present_items:\n",
        "        extracted_data.append({'Quantity': 0, 'Quantity Name': item_name, 'Update Time (ms)': None})\n",
        "\n",
        "    return extracted_data\n",
        "\n",
        "# Example input text\n",
        "x = \"\"\"\n",
        "Jacket: 2 3.5ms\n",
        "Helmet: 1 2.2ms\n",
        "Footwear: 3 4.1ms\n",
        "Gloves: 4 5.7ms\n",
        "\"\"\"\n",
        "\n",
        "result = extract_helmet_jacket_data(x)\n",
        "\n",
        "# Create a DataFrame from the extracted data\n",
        "df = pd.DataFrame(result)\n",
        "\n",
        "# Display the data in a table format\n",
        "filtered_df = df[df['Quantity Name']=='Jacket']\n",
        "df.to_excel('filtered_data.xlsx', index=False)\n",
        "print(filtered_df)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}